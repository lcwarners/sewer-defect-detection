{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBaXDwV9vB8v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dropout, Input, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating batches for the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK9q9N3nvH4A"
   },
   "outputs": [],
   "source": [
    "#find data sets. note these are not made public due to confidential nature.\n",
    "train_path = \"train_data/train\"\n",
    "valid_path = \"train_data/valid\"\n",
    "test_path = \"train_data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puQLmPcDvIew"
   },
   "outputs": [],
   "source": [
    "#generation of batches; batch_size can be adapted based on availability of GPU.\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ipI-Rr0vYUL"
   },
   "outputs": [],
   "source": [
    "#download the model, top is not included in order to do transfer learning.\n",
    "resnet50_model = tf.keras.applications.resnet50.ResNet50(include_top=False,input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwclj5px9jPf"
   },
   "outputs": [],
   "source": [
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-ogcJRavs19"
   },
   "outputs": [],
   "source": [
    "#additional dense layers and dropout to successfully carry out transfer learning. Original output is flattened such that the original model functions as feature extractor.\n",
    "top_layers = resnet50_model.output\n",
    "top_layers = Flatten(name=\"top_flattening\")(top_layers)\n",
    "top_layers = Dense(units=1024,activation=\"ReLU\",name=\"first_dense_top\")(top_layers)\n",
    "top_layers = Dropout(0.5,name=\"dropout_top\")(top_layers)\n",
    "top_layers = Dense(units=3, activation=\"softmax\",name=\"linear_output\")(top_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIxPfk0nBMlz"
   },
   "outputs": [],
   "source": [
    "#the resnet model and the output layers are joined together\n",
    "model = Model(inputs=resnet50_model.input, outputs=top_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE21zCEAKATB"
   },
   "outputs": [],
   "source": [
    "#original model is set to be untrainable.\n",
    "for layer in resnet50_model.layers:\n",
    "\tlayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkzqCxydvwnv"
   },
   "outputs": [],
   "source": [
    "#the range of different learning rates that will be compared.\n",
    "learning_rate = np.logspace(-4,-2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmdjQS69v0Mg"
   },
   "outputs": [],
   "source": [
    "#comparison of the learning rates and epochs necessary to compute them.\n",
    "for lr in learning_rate:\n",
    "  print(\"--------------------\")\n",
    "  print(\"learning rate = \", lr)\n",
    "  print(\"--------------------\")\n",
    "  model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  model.fit(train_batches,\n",
    "            steps_per_epoch=len(train_batches),\n",
    "            validation_data=valid_batches,\n",
    "            validation_steps=len(valid_batches),\n",
    "            epochs=5\n",
    "  )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
