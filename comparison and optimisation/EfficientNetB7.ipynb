{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNetB7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5NIgT_hfhQo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/ML project 2/\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "HHXXVYX-gDHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use GPU insofar possible\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "id": "tPScTqB4gHAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dropout, Input, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "nE_6M8YGgMIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find data sets. note these are not made public due to confidential nature.\n",
        "train_path = \"train_data/train\"\n",
        "valid_path = \"train_data/valid\"\n",
        "test_path = \"train_data/test\""
      ],
      "metadata": {
        "id": "ch-P-C91gTNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generation of batches; batch_size can be adapted based on availability of GPU.\n",
        "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input) \\\n",
        "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64)\n",
        "\n",
        "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input) \\\n",
        "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64)\n",
        "\n",
        "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input) \\\n",
        "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['Fissure', 'Racines', 'Normal'], batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ox2bcaX8gVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the model, top is not included in order to do transfer learning.\n",
        "efficientnet_model = tf.keras.applications.efficientnet.EfficientNetB7(include_top=False,input_tensor=Input(shape=(224, 224, 3)))"
      ],
      "metadata": {
        "id": "Siv63cSRiifH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "id": "6FrACp41iq5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#additional dense layers and dropout to successfully carry out transfer learning. Original output is flattened such that the original model functions as feature extractor.\n",
        "top_layers = efficientnet_model.output\n",
        "top_layers = Flatten(name=\"top_flattening\")(top_layers)\n",
        "top_layers = Dense(1024, activation=\"ReLU\",name=\"first_dense_top\")(top_layers)\n",
        "top_layers = Dropout(0.5,name=\"top_dropout\")(top_layers)\n",
        "top_layers = Dense(units=3, activation=\"softmax\",name=\"linear_output\")(top_layers)"
      ],
      "metadata": {
        "id": "rWK-WaYCivoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the efficientnet model and the output layers are joined together\n",
        "model = Model(inputs=efficientnet_model.input, outputs=top_layers)"
      ],
      "metadata": {
        "id": "PWrZ4ryEjhyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#original model is set to be untrainable.\n",
        "for layer in efficientnet_model.layers:\n",
        "\tlayer.trainable = False"
      ],
      "metadata": {
        "id": "MhM-hUSXjt6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the range of different learning rates that will be compared.\n",
        "learning_rate = np.logspace(-4,-2,4)"
      ],
      "metadata": {
        "id": "qTmLLS7nj2WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#comparison of the learning rates and epochs necessary to compute them.\n",
        "for lr in learning_rate:\n",
        "  print(\"--------------------\")\n",
        "  print(\"learning rate = \",lr)\n",
        "  print(\"--------------------\")\n",
        "  model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_batches,\n",
        "            steps_per_epoch=len(train_batches),\n",
        "            validation_data=valid_batches,\n",
        "            validation_steps=len(valid_batches),\n",
        "            epochs=5\n",
        "  )"
      ],
      "metadata": {
        "id": "c3rj_clBkC_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}